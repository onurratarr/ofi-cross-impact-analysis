{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332e5689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\onurr\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\onurr\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\onurr\\anaconda3\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\onurr\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\onurr\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: et_xmlfile in c:\\users\\onurr\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\onurr\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e81e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory:\n",
      "xnas-itch-20241219.mbp-10.csv\n",
      "xnas-itch-amgn-20241219.mbp-10.csv\n",
      "xnas-itch-marathon-20241219.mbp-10.csv\n",
      "xnas-itch-nvdia-20241219.mbp-10.csv\n",
      "xnas-itch-tsla-20241219.mbp-10.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Define data directory path\n",
    "DATA_DIR = Path(r'C:\\Users\\onurr\\ofi-cross-impact-analysis\\data')\n",
    "\n",
    "# First, let's see what files are actually in the directory\n",
    "print(\"Files in directory:\")\n",
    "for file in DATA_DIR.glob('*'):\n",
    "    print(file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2633ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: xnas-itch-20241219.mbp-10.csv\n",
      "Columns: ['ts_recv', 'ts_event', 'rtype', 'publisher_id', 'instrument_id', 'action', 'side', 'depth', 'price', 'size', 'flags', 'ts_in_delta', 'sequence', 'bid_px_00', 'ask_px_00', 'bid_sz_00', 'ask_sz_00', 'bid_ct_00', 'ask_ct_00', 'bid_px_01', 'ask_px_01', 'bid_sz_01', 'ask_sz_01', 'bid_ct_01', 'ask_ct_01', 'bid_px_02', 'ask_px_02', 'bid_sz_02', 'ask_sz_02', 'bid_ct_02', 'ask_ct_02', 'bid_px_03', 'ask_px_03', 'bid_sz_03', 'ask_sz_03', 'bid_ct_03', 'ask_ct_03', 'bid_px_04', 'ask_px_04', 'bid_sz_04', 'ask_sz_04', 'bid_ct_04', 'ask_ct_04', 'bid_px_05', 'ask_px_05', 'bid_sz_05', 'ask_sz_05', 'bid_ct_05', 'ask_ct_05', 'bid_px_06', 'ask_px_06', 'bid_sz_06', 'ask_sz_06', 'bid_ct_06', 'ask_ct_06', 'bid_px_07', 'ask_px_07', 'bid_sz_07', 'ask_sz_07', 'bid_ct_07', 'ask_ct_07', 'bid_px_08', 'ask_px_08', 'bid_sz_08', 'ask_sz_08', 'bid_ct_08', 'ask_ct_08', 'bid_px_09', 'ask_px_09', 'bid_sz_09', 'ask_sz_09', 'bid_ct_09', 'ask_ct_09', 'symbol']\n",
      "\n",
      "First row sample:\n",
      "ts_recv          2024-12-19T09:00:00.087834033Z\n",
      "ts_event         2024-12-19T09:00:00.087665637Z\n",
      "rtype                                        10\n",
      "publisher_id                                  2\n",
      "instrument_id                              2022\n",
      "                              ...              \n",
      "bid_sz_09                                     0\n",
      "ask_sz_09                                     0\n",
      "bid_ct_09                                     0\n",
      "ask_ct_09                                     0\n",
      "symbol                                      BKR\n",
      "Name: 0, Length: 74, dtype: object\n",
      "\n",
      "Data types:\n",
      "ts_recv          object\n",
      "ts_event         object\n",
      "rtype             int64\n",
      "publisher_id      int64\n",
      "instrument_id     int64\n",
      "                  ...  \n",
      "bid_sz_09         int64\n",
      "ask_sz_09         int64\n",
      "bid_ct_09         int64\n",
      "ask_ct_09         int64\n",
      "symbol           object\n",
      "Length: 74, dtype: object\n",
      "\n",
      "File: xnas-itch-amgn-20241219.mbp-10.csv\n",
      "Columns: ['ts_recv', 'ts_event', 'rtype', 'publisher_id', 'instrument_id', 'action', 'side', 'depth', 'price', 'size', 'flags', 'ts_in_delta', 'sequence', 'bid_px_00', 'ask_px_00', 'bid_sz_00', 'ask_sz_00', 'bid_ct_00', 'ask_ct_00', 'bid_px_01', 'ask_px_01', 'bid_sz_01', 'ask_sz_01', 'bid_ct_01', 'ask_ct_01', 'bid_px_02', 'ask_px_02', 'bid_sz_02', 'ask_sz_02', 'bid_ct_02', 'ask_ct_02', 'bid_px_03', 'ask_px_03', 'bid_sz_03', 'ask_sz_03', 'bid_ct_03', 'ask_ct_03', 'bid_px_04', 'ask_px_04', 'bid_sz_04', 'ask_sz_04', 'bid_ct_04', 'ask_ct_04', 'bid_px_05', 'ask_px_05', 'bid_sz_05', 'ask_sz_05', 'bid_ct_05', 'ask_ct_05', 'bid_px_06', 'ask_px_06', 'bid_sz_06', 'ask_sz_06', 'bid_ct_06', 'ask_ct_06', 'bid_px_07', 'ask_px_07', 'bid_sz_07', 'ask_sz_07', 'bid_ct_07', 'ask_ct_07', 'bid_px_08', 'ask_px_08', 'bid_sz_08', 'ask_sz_08', 'bid_ct_08', 'ask_ct_08', 'bid_px_09', 'ask_px_09', 'bid_sz_09', 'ask_sz_09', 'bid_ct_09', 'ask_ct_09', 'symbol']\n",
      "\n",
      "First row sample:\n",
      "ts_recv          2024-12-19T09:00:00.018983101Z\n",
      "ts_event         2024-12-19T09:00:00.018816317Z\n",
      "rtype                                        10\n",
      "publisher_id                                  2\n",
      "instrument_id                             11667\n",
      "                              ...              \n",
      "bid_sz_09                                     0\n",
      "ask_sz_09                                     0\n",
      "bid_ct_09                                     0\n",
      "ask_ct_09                                     0\n",
      "symbol                                     NVDA\n",
      "Name: 0, Length: 74, dtype: object\n",
      "\n",
      "Data types:\n",
      "ts_recv          object\n",
      "ts_event         object\n",
      "rtype             int64\n",
      "publisher_id      int64\n",
      "instrument_id     int64\n",
      "                  ...  \n",
      "bid_sz_09         int64\n",
      "ask_sz_09         int64\n",
      "bid_ct_09         int64\n",
      "ask_ct_09         int64\n",
      "symbol           object\n",
      "Length: 74, dtype: object\n",
      "\n",
      "File: xnas-itch-marathon-20241219.mbp-10.csv\n",
      "Columns: ['ts_recv', 'ts_event', 'rtype', 'publisher_id', 'instrument_id', 'action', 'side', 'depth', 'price', 'size', 'flags', 'ts_in_delta', 'sequence', 'bid_px_00', 'ask_px_00', 'bid_sz_00', 'ask_sz_00', 'bid_ct_00', 'ask_ct_00', 'bid_px_01', 'ask_px_01', 'bid_sz_01', 'ask_sz_01', 'bid_ct_01', 'ask_ct_01', 'bid_px_02', 'ask_px_02', 'bid_sz_02', 'ask_sz_02', 'bid_ct_02', 'ask_ct_02', 'bid_px_03', 'ask_px_03', 'bid_sz_03', 'ask_sz_03', 'bid_ct_03', 'ask_ct_03', 'bid_px_04', 'ask_px_04', 'bid_sz_04', 'ask_sz_04', 'bid_ct_04', 'ask_ct_04', 'bid_px_05', 'ask_px_05', 'bid_sz_05', 'ask_sz_05', 'bid_ct_05', 'ask_ct_05', 'bid_px_06', 'ask_px_06', 'bid_sz_06', 'ask_sz_06', 'bid_ct_06', 'ask_ct_06', 'bid_px_07', 'ask_px_07', 'bid_sz_07', 'ask_sz_07', 'bid_ct_07', 'ask_ct_07', 'bid_px_08', 'ask_px_08', 'bid_sz_08', 'ask_sz_08', 'bid_ct_08', 'ask_ct_08', 'bid_px_09', 'ask_px_09', 'bid_sz_09', 'ask_sz_09', 'bid_ct_09', 'ask_ct_09', 'symbol']\n",
      "\n",
      "First row sample:\n",
      "ts_recv          2024-12-19T09:00:00.020283585Z\n",
      "ts_event         2024-12-19T09:00:00.020117066Z\n",
      "rtype                                        10\n",
      "publisher_id                                  2\n",
      "instrument_id                             10238\n",
      "                              ...              \n",
      "bid_sz_09                                     0\n",
      "ask_sz_09                                     0\n",
      "bid_ct_09                                     0\n",
      "ask_ct_09                                     0\n",
      "symbol                                     MARA\n",
      "Name: 0, Length: 74, dtype: object\n",
      "\n",
      "Data types:\n",
      "ts_recv          object\n",
      "ts_event         object\n",
      "rtype             int64\n",
      "publisher_id      int64\n",
      "instrument_id     int64\n",
      "                  ...  \n",
      "bid_sz_09         int64\n",
      "ask_sz_09         int64\n",
      "bid_ct_09         int64\n",
      "ask_ct_09         int64\n",
      "symbol           object\n",
      "Length: 74, dtype: object\n",
      "\n",
      "File: xnas-itch-nvdia-20241219.mbp-10.csv\n",
      "Columns: ['ts_recv', 'ts_event', 'rtype', 'publisher_id', 'instrument_id', 'action', 'side', 'depth', 'price', 'size', 'flags', 'ts_in_delta', 'sequence', 'bid_px_00', 'ask_px_00', 'bid_sz_00', 'ask_sz_00', 'bid_ct_00', 'ask_ct_00', 'bid_px_01', 'ask_px_01', 'bid_sz_01', 'ask_sz_01', 'bid_ct_01', 'ask_ct_01', 'bid_px_02', 'ask_px_02', 'bid_sz_02', 'ask_sz_02', 'bid_ct_02', 'ask_ct_02', 'bid_px_03', 'ask_px_03', 'bid_sz_03', 'ask_sz_03', 'bid_ct_03', 'ask_ct_03', 'bid_px_04', 'ask_px_04', 'bid_sz_04', 'ask_sz_04', 'bid_ct_04', 'ask_ct_04', 'bid_px_05', 'ask_px_05', 'bid_sz_05', 'ask_sz_05', 'bid_ct_05', 'ask_ct_05', 'bid_px_06', 'ask_px_06', 'bid_sz_06', 'ask_sz_06', 'bid_ct_06', 'ask_ct_06', 'bid_px_07', 'ask_px_07', 'bid_sz_07', 'ask_sz_07', 'bid_ct_07', 'ask_ct_07', 'bid_px_08', 'ask_px_08', 'bid_sz_08', 'ask_sz_08', 'bid_ct_08', 'ask_ct_08', 'bid_px_09', 'ask_px_09', 'bid_sz_09', 'ask_sz_09', 'bid_ct_09', 'ask_ct_09', 'symbol']\n",
      "\n",
      "First row sample:\n",
      "ts_recv          2024-12-19T09:00:00.018983101Z\n",
      "ts_event         2024-12-19T09:00:00.018816317Z\n",
      "rtype                                        10\n",
      "publisher_id                                  2\n",
      "instrument_id                             11667\n",
      "                              ...              \n",
      "bid_sz_09                                     0\n",
      "ask_sz_09                                     0\n",
      "bid_ct_09                                     0\n",
      "ask_ct_09                                     0\n",
      "symbol                                     NVDA\n",
      "Name: 0, Length: 74, dtype: object\n",
      "\n",
      "Data types:\n",
      "ts_recv          object\n",
      "ts_event         object\n",
      "rtype             int64\n",
      "publisher_id      int64\n",
      "instrument_id     int64\n",
      "                  ...  \n",
      "bid_sz_09         int64\n",
      "ask_sz_09         int64\n",
      "bid_ct_09         int64\n",
      "ask_ct_09         int64\n",
      "symbol           object\n",
      "Length: 74, dtype: object\n",
      "\n",
      "File: xnas-itch-tsla-20241219.mbp-10.csv\n",
      "Columns: ['ts_recv', 'ts_event', 'rtype', 'publisher_id', 'instrument_id', 'action', 'side', 'depth', 'price', 'size', 'flags', 'ts_in_delta', 'sequence', 'bid_px_00', 'ask_px_00', 'bid_sz_00', 'ask_sz_00', 'bid_ct_00', 'ask_ct_00', 'bid_px_01', 'ask_px_01', 'bid_sz_01', 'ask_sz_01', 'bid_ct_01', 'ask_ct_01', 'bid_px_02', 'ask_px_02', 'bid_sz_02', 'ask_sz_02', 'bid_ct_02', 'ask_ct_02', 'bid_px_03', 'ask_px_03', 'bid_sz_03', 'ask_sz_03', 'bid_ct_03', 'ask_ct_03', 'bid_px_04', 'ask_px_04', 'bid_sz_04', 'ask_sz_04', 'bid_ct_04', 'ask_ct_04', 'bid_px_05', 'ask_px_05', 'bid_sz_05', 'ask_sz_05', 'bid_ct_05', 'ask_ct_05', 'bid_px_06', 'ask_px_06', 'bid_sz_06', 'ask_sz_06', 'bid_ct_06', 'ask_ct_06', 'bid_px_07', 'ask_px_07', 'bid_sz_07', 'ask_sz_07', 'bid_ct_07', 'ask_ct_07', 'bid_px_08', 'ask_px_08', 'bid_sz_08', 'ask_sz_08', 'bid_ct_08', 'ask_ct_08', 'bid_px_09', 'ask_px_09', 'bid_sz_09', 'ask_sz_09', 'bid_ct_09', 'ask_ct_09', 'symbol']\n",
      "\n",
      "First row sample:\n",
      "ts_recv          2024-12-19T09:00:00.012077078Z\n",
      "ts_event         2024-12-19T09:00:00.011910681Z\n",
      "rtype                                        10\n",
      "publisher_id                                  2\n",
      "instrument_id                             16244\n",
      "                              ...              \n",
      "bid_sz_09                                     0\n",
      "ask_sz_09                                     0\n",
      "bid_ct_09                                     0\n",
      "ask_ct_09                                     0\n",
      "symbol                                     TSLA\n",
      "Name: 0, Length: 74, dtype: object\n",
      "\n",
      "Data types:\n",
      "ts_recv          object\n",
      "ts_event         object\n",
      "rtype             int64\n",
      "publisher_id      int64\n",
      "instrument_id     int64\n",
      "                  ...  \n",
      "bid_sz_09         int64\n",
      "ask_sz_09         int64\n",
      "bid_ct_09         int64\n",
      "ask_ct_09         int64\n",
      "symbol           object\n",
      "Length: 74, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define data directory path\n",
    "DATA_DIR = Path(r'C:\\Users\\onurr\\ofi-cross-impact-analysis\\data')\n",
    "\n",
    "# List of files to process\n",
    "files = [\n",
    "    'xnas-itch-20241219.mbp-10.csv',\n",
    "    'xnas-itch-amgn-20241219.mbp-10.csv',\n",
    "    'xnas-itch-marathon-20241219.mbp-10.csv',\n",
    "    'xnas-itch-nvdia-20241219.mbp-10.csv',\n",
    "    'xnas-itch-tsla-20241219.mbp-10.csv'\n",
    "]\n",
    "\n",
    "# Function to examine file structure\n",
    "def examine_file_structure(file_path):\n",
    "    try:\n",
    "        # Read first few rows of the file\n",
    "        df = pd.read_csv(file_path, nrows=5)\n",
    "        \n",
    "        print(f\"\\nFile: {file_path.name}\")\n",
    "        print(\"Columns:\", df.columns.tolist())\n",
    "        print(\"\\nFirst row sample:\")\n",
    "        print(df.iloc[0])\n",
    "        print(\"\\nData types:\")\n",
    "        print(df.dtypes)\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Process each file\n",
    "for file in files:\n",
    "    file_path = DATA_DIR / file\n",
    "    examine_file_structure(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3170c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking project structure...\n",
      "✓ data/ exists\n",
      "✓ notebooks/ exists\n",
      "✓ scripts/ exists\n",
      "✓ results/ exists\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define project root directory\n",
    "project_root = Path(r'C:\\Users\\onurr\\ofi-cross-impact-analysis')\n",
    "\n",
    "# Check project structure\n",
    "required_dirs = ['data', 'notebooks', 'scripts', 'results']\n",
    "\n",
    "print(\"Checking project structure...\")\n",
    "for dir_name in required_dirs:\n",
    "    dir_path = project_root / dir_name\n",
    "    if dir_path.exists():\n",
    "        print(f\"✓ {dir_name}/ exists\")\n",
    "    else:\n",
    "        print(f\"✗ {dir_name}/ not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dece2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory found\n",
      "✓ Found: xnas-itch-20241219.mbp-10.csv\n",
      "✓ Found: xnas-itch-amgn-20241219.mbp-10.csv\n",
      "✓ Found: xnas-itch-marathon-20241219.mbp-10.csv\n",
      "✓ Found: xnas-itch-nvdia-20241219.mbp-10.csv\n",
      "✓ Found: xnas-itch-tsla-20241219.mbp-10.csv\n"
     ]
    }
   ],
   "source": [
    "# Check if all 5 required data files are in the correct location\n",
    "from pathlib import Path\n",
    "\n",
    "# Define data directory path\n",
    "DATA_DIR = Path(r'C:\\Users\\onurr\\ofi-cross-impact-analysis\\data')\n",
    "\n",
    "# List of required files\n",
    "required_files = [\n",
    "    'xnas-itch-20241219.mbp-10.csv',\n",
    "    'xnas-itch-amgn-20241219.mbp-10.csv',\n",
    "    'xnas-itch-marathon-20241219.mbp-10.csv',\n",
    "    'xnas-itch-nvdia-20241219.mbp-10.csv',\n",
    "    'xnas-itch-tsla-20241219.mbp-10.csv'\n",
    "]\n",
    "\n",
    "# Check if data directory exists\n",
    "if not DATA_DIR.exists():\n",
    "    print(f\"Data directory not found: {DATA_DIR}\")\n",
    "else:\n",
    "    print(\"Data directory found\")\n",
    "    # Check each required file\n",
    "    for file_name in required_files:\n",
    "        file_path = DATA_DIR / file_name\n",
    "        if file_path.exists():\n",
    "            print(f\"✓ Found: {file_name}\")\n",
    "        else:\n",
    "            print(f\"✗ Missing: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3170694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial README.md file\n",
    "readme_content = \"\"\"# Order Flow Imbalance (OFI) Cross-Impact Analysis\n",
    "\n",
    "This project analyzes the cross-impact of Order Flow Imbalance (OFI) across multiple stocks.\n",
    "\n",
    "## Project Structure\n",
    "- `data/`: Contains the raw market data files\n",
    "- `notebooks/`: Jupyter notebooks for analysis\n",
    "- `scripts/`: Python scripts for data processing\n",
    "- `results/`: Output files and visualizations\n",
    "\n",
    "## Data Description\n",
    "Working with high-frequency data for 5 Nasdaq stocks:\n",
    "- BKR (Baker Hughes)\n",
    "- NVDA (NVIDIA)\n",
    "- MARA (Marathon Digital)\n",
    "- TSLA (Tesla)\n",
    "\"\"\"\n",
    "\n",
    "with open(project_root / 'README.md', 'w') as f:\n",
    "    f.write(readme_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8547c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create requirements.txt with necessary packages\n",
    "requirements_content = \"\"\"pandas\n",
    "numpy\n",
    "matplotlib\n",
    "seaborn\n",
    "scikit-learn\n",
    "jupyter\n",
    "openpyxl\n",
    "\"\"\"\n",
    "\n",
    "with open(project_root / 'requirements.txt', 'w') as f:\n",
    "    f.write(requirements_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e65a8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create main analysis script\n",
    "script_content = \"\"\"import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def calculate_ofi(df, level=5):\n",
    "    '''\n",
    "    Calculate Order Flow Imbalance for given order book data\n",
    "    Parameters:\n",
    "    - df: DataFrame with order book data\n",
    "    - level: Number of price levels to consider (default=5)\n",
    "    '''\n",
    "    ofi_levels = []\n",
    "    \n",
    "    for i in range(level):\n",
    "        # Calculate OFI for each level\n",
    "        bid_size = df[f'bid_sz_{i:02d}']\n",
    "        ask_size = df[f'ask_sz_{i:02d}']\n",
    "        \n",
    "        # Basic OFI calculation: bid size - ask size\n",
    "        ofi = bid_size - ask_size\n",
    "        ofi_levels.append(ofi)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'ts_event': df['ts_event'],\n",
    "        'symbol': df['symbol'],\n",
    "        **{f'ofi_level_{i}': ofi_levels[i] for i in range(level)}\n",
    "    })\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    DATA_DIR = Path(__file__).parent.parent / 'data'\n",
    "    # Process first 1000 rows as a test\n",
    "    df = pd.read_csv(DATA_DIR / 'xnas-itch-tsla-20241219.mbp-10.csv', nrows=1000)\n",
    "    ofi_result = calculate_ofi(df)\n",
    "    print(ofi_result.head())\n",
    "\"\"\"\n",
    "\n",
    "# Write the script to a file\n",
    "script_path = project_root / 'scripts' / 'calculate_ofi.py'\n",
    "with open(script_path, 'w') as f:\n",
    "    f.write(script_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efa5a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create core analysis scripts\n",
    "scripts = {\n",
    "    'utils.py': \"\"\"import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def load_data(file_path, sample_size=None):\n",
    "    '''Load and preprocess order book data'''\n",
    "    df = pd.read_csv(file_path, nrows=sample_size)\n",
    "    df['ts_event'] = pd.to_datetime(df['ts_event'])\n",
    "    return df.sort_values('ts_event')\n",
    "\n",
    "def calculate_ofi(df, level=5):\n",
    "    '''Calculate OFI metrics for multiple levels'''\n",
    "    ofi_levels = []\n",
    "    for i in range(level):\n",
    "        bid_size = df[f'bid_sz_{i:02d}']\n",
    "        ask_size = df[f'ask_sz_{i:02d}']\n",
    "        ofi = bid_size - ask_size\n",
    "        ofi_levels.append(ofi)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'ts_event': df['ts_event'],\n",
    "        'symbol': df['symbol'],\n",
    "        **{f'ofi_level_{i}': ofi_levels[i] for i in range(level)}\n",
    "    })\n",
    "\"\"\",\n",
    "\n",
    "    'analysis.py': \"\"\"import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from .utils import load_data, calculate_ofi\n",
    "\n",
    "def process_stock_data(file_path, sample_size=None):\n",
    "    '''Process single stock data and calculate OFI'''\n",
    "    df = load_data(file_path, sample_size)\n",
    "    return calculate_ofi(df)\n",
    "\n",
    "def calculate_cross_impact(ofi_data, price_changes):\n",
    "    '''Calculate cross-impact between stocks'''\n",
    "    return np.corrcoef(ofi_data.T)\n",
    "\n",
    "def main():\n",
    "    DATA_DIR = Path(__file__).parent.parent / 'data'\n",
    "    files = list(DATA_DIR.glob('xnas-itch-*.csv'))\n",
    "    \n",
    "    # Process each stock\n",
    "    all_ofi = {}\n",
    "    for file in files:\n",
    "        stock_ofi = process_stock_data(file)\n",
    "        symbol = stock_ofi['symbol'].iloc[0]\n",
    "        all_ofi[symbol] = stock_ofi\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\",\n",
    "\n",
    "    'visualization.py': \"\"\"import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_ofi_heatmap(cross_impact_matrix, symbols, save_path=None):\n",
    "    '''Create heatmap of cross-impact relationships'''\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cross_impact_matrix, \n",
    "                xticklabels=symbols,\n",
    "                yticklabels=symbols,\n",
    "                cmap='coolwarm',\n",
    "                center=0)\n",
    "    plt.title('Cross-Impact of OFI Between Stocks')\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# Write all scripts\n",
    "for filename, content in scripts.items():\n",
    "    script_path = project_root / 'scripts' / filename\n",
    "    with open(script_path, 'w') as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cd29dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_content = \"\"\"{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Order Flow Imbalance (OFI) Analysis\\\\n\",\n",
    "    \"This notebook implements the analysis of Order Flow Imbalance cross-impact across multiple stocks.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"import sys\\\\n\",\n",
    "    \"from pathlib import Path\\\\n\",\n",
    "    \"sys.path.append(str(Path.cwd().parent / 'scripts'))\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"import pandas as pd\\\\n\",\n",
    "    \"import numpy as np\\\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\\\n\",\n",
    "    \"import seaborn as sns\\\\n\",\n",
    "    \"from utils import load_data, calculate_ofi\\\\n\",\n",
    "    \"from analysis import process_stock_data, calculate_cross_impact\\\\n\",\n",
    "    \"from visualization import plot_ofi_heatmap\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Load and Process Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"DATA_DIR = Path.cwd().parent / 'data'\\\\n\",\n",
    "    \"files = list(DATA_DIR.glob('xnas-itch-*.csv'))\\\\n\",\n",
    "    \"\\\\n\",\n",
    "    \"# Process each stock\\\\n\",\n",
    "    \"all_ofi = {}\\\\n\",\n",
    "    \"for file in files:\\\\n\",\n",
    "    \"    stock_ofi = process_stock_data(file)\\\\n\",\n",
    "    \"    symbol = stock_ofi['symbol'].iloc[0]\\\\n\",\n",
    "    \"    all_ofi[symbol] = stock_ofi\\\\n\",\n",
    "    \"    print(f'Processed {symbol}')\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "notebook_path = project_root / 'notebooks' / 'ofi_analysis.ipynb'\n",
    "with open(notebook_path, 'w') as f:\n",
    "    f.write(notebook_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7115d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_script_content = \"\"\"import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from utils import load_data, calculate_ofi\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def test_pipeline():\n",
    "    try:\n",
    "        # Set paths\n",
    "        DATA_DIR = Path(__file__).parent.parent / 'data'\n",
    "        \n",
    "        # Test with TSLA data first\n",
    "        test_file = DATA_DIR / 'xnas-itch-tsla-20241219.mbp-10.csv'\n",
    "        \n",
    "        # Load first 1000 rows\n",
    "        logger.info(\"Loading test data...\")\n",
    "        df = load_data(test_file, sample_size=1000)\n",
    "        \n",
    "        # Calculate OFI\n",
    "        logger.info(\"Calculating OFI...\")\n",
    "        ofi_results = calculate_ofi(df)\n",
    "        \n",
    "        # Basic statistics\n",
    "        logger.info(\"\\\\nOFI Statistics:\")\n",
    "        print(ofi_results.describe())\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in test pipeline: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_pipeline()\"\"\"\n",
    "\n",
    "# Write test script\n",
    "test_script_path = project_root / 'scripts' / 'test_pipeline.py'\n",
    "with open(test_script_path, 'w') as f:\n",
    "    f.write(test_script_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eff5f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-05 11:44:19,454 - INFO - Loading test data...\n",
      "2025-01-05 11:44:19,489 - INFO - Calculating OFI...\n",
      "2025-01-05 11:44:19,491 - INFO - \n",
      "OFI Statistics:\n",
      "       ofi_level_0  ofi_level_1  ofi_level_2  ofi_level_3  ofi_level_4\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000\n",
      "mean     12.771000   -39.029000  -184.686000  -158.945000  -169.527000\n",
      "std     173.487932   224.798213   230.994753   225.855522   248.655989\n",
      "min    -499.000000  -499.000000  -499.000000  -516.000000  -516.000000\n",
      "25%     -66.000000  -165.000000  -450.000000  -408.000000  -474.000000\n",
      "50%     -16.000000    -4.500000  -165.000000  -100.000000  -124.000000\n",
      "75%      90.000000    80.000000   -10.000000    14.000000     9.000000\n",
      "max     450.000000   409.000000   359.000000   358.000000   700.000000\n"
     ]
    }
   ],
   "source": [
    "# Run test pipeline from scripts directory\n",
    "from importlib import import_module\n",
    "import sys\n",
    "\n",
    "# Add scripts directory to path\n",
    "scripts_dir = project_root / 'scripts'\n",
    "if str(scripts_dir) not in sys.path:\n",
    "    sys.path.append(str(scripts_dir))\n",
    "\n",
    "# Import and run test\n",
    "try:\n",
    "    test_pipeline = import_module('test_pipeline')\n",
    "    test_pipeline.test_pipeline()\n",
    "except Exception as e:\n",
    "    print(f\"Error running test pipeline: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da661611",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_analysis_content = \"\"\"import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from utils import load_data, calculate_ofi\n",
    "from visualization import plot_ofi_heatmap\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def run_full_analysis():\n",
    "    try:\n",
    "        # Set paths\n",
    "        DATA_DIR = Path(__file__).parent.parent / 'data'\n",
    "        RESULTS_DIR = Path(__file__).parent.parent / 'results'\n",
    "        RESULTS_DIR.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Process all files\n",
    "        all_stocks_ofi = {}\n",
    "        files = list(DATA_DIR.glob('xnas-itch-*.csv'))\n",
    "        \n",
    "        for file in files:\n",
    "            logger.info(f\"Processing {file.name}\")\n",
    "            df = load_data(file)\n",
    "            ofi_results = calculate_ofi(df)\n",
    "            symbol = ofi_results['symbol'].iloc[0]\n",
    "            all_stocks_ofi[symbol] = ofi_results\n",
    "            \n",
    "            # Save individual stock results\n",
    "            output_file = RESULTS_DIR / f'ofi_results_{symbol}.csv'\n",
    "            ofi_results.to_csv(output_file, index=False)\n",
    "            logger.info(f\"Saved results for {symbol}\")\n",
    "            \n",
    "        # Calculate cross-impacts\n",
    "        logger.info(\"Calculating cross-impacts...\")\n",
    "        symbols = list(all_stocks_ofi.keys())\n",
    "        cross_impact_matrix = np.zeros((len(symbols), len(symbols)))\n",
    "        \n",
    "        for i, sym1 in enumerate(symbols):\n",
    "            for j, sym2 in enumerate(symbols):\n",
    "                corr = all_stocks_ofi[sym1]['ofi_level_0'].corr(all_stocks_ofi[sym2]['ofi_level_0'])\n",
    "                cross_impact_matrix[i, j] = corr\n",
    "        \n",
    "        # Create and save heatmap\n",
    "        plot_ofi_heatmap(cross_impact_matrix, symbols, \n",
    "                        save_path=RESULTS_DIR / 'cross_impact_heatmap.png')\n",
    "        \n",
    "        # Save cross-impact matrix\n",
    "        pd.DataFrame(cross_impact_matrix, \n",
    "                    index=symbols, \n",
    "                    columns=symbols).to_csv(RESULTS_DIR / 'cross_impact_matrix.csv')\n",
    "        \n",
    "        logger.info(\"Analysis completed successfully\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in full analysis: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_analysis()\n",
    "\"\"\"\n",
    "\n",
    "# Write full analysis script\n",
    "analysis_path = project_root / 'scripts' / 'full_analysis.py'\n",
    "with open(analysis_path, 'w') as f:\n",
    "    f.write(full_analysis_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d41394da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-05 11:45:07,254 - INFO - Processing xnas-itch-20241219.mbp-10.csv\n",
      "2025-01-05 11:45:11,045 - INFO - Saved results for BKR\n",
      "2025-01-05 11:45:11,046 - INFO - Processing xnas-itch-amgn-20241219.mbp-10.csv\n",
      "2025-01-05 11:46:29,292 - INFO - Saved results for NVDA\n",
      "2025-01-05 11:46:29,307 - INFO - Processing xnas-itch-marathon-20241219.mbp-10.csv\n",
      "2025-01-05 11:46:36,665 - INFO - Saved results for MARA\n",
      "2025-01-05 11:46:36,665 - INFO - Processing xnas-itch-nvdia-20241219.mbp-10.csv\n",
      "2025-01-05 11:47:44,302 - INFO - Saved results for NVDA\n",
      "2025-01-05 11:47:44,309 - INFO - Processing xnas-itch-tsla-20241219.mbp-10.csv\n",
      "2025-01-05 11:48:17,515 - INFO - Saved results for TSLA\n",
      "2025-01-05 11:48:17,519 - INFO - Calculating cross-impacts...\n",
      "2025-01-05 11:48:19,587 - INFO - Analysis completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Run full analysis\n",
    "try:\n",
    "    import full_analysis\n",
    "    full_analysis.run_full_analysis()\n",
    "except Exception as e:\n",
    "    print(f\"Error running full analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c164bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Results Files:\n",
      "- .gitkeep\n",
      "- cross_impact_heatmap.png\n",
      "- cross_impact_matrix.csv\n",
      "- ofi_results_BKR.csv\n",
      "- ofi_results_MARA.csv\n",
      "- ofi_results_NVDA.csv\n",
      "- ofi_results_TSLA.csv\n"
     ]
    }
   ],
   "source": [
    "# Check all generated files\n",
    "results_dir = project_root / 'results'\n",
    "print(\"Generated Results Files:\")\n",
    "for file in results_dir.glob('*'):\n",
    "    print(f\"- {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a00a33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Impact Matrix:\n",
      "           BKR      NVDA      MARA      TSLA\n",
      "BKR   1.000000  0.009360 -0.026643  0.005796\n",
      "NVDA  0.009360  1.000000 -0.013308  0.046677\n",
      "MARA -0.026643 -0.013308  1.000000 -0.027286\n",
      "TSLA  0.005796  0.046677 -0.027286  1.000000\n",
      "\n",
      "TSLA OFI Results (first few rows):\n",
      "                              ts_event symbol  ofi_level_0  ofi_level_1  \\\n",
      "0  2024-12-19 09:00:00.011910681+00:00   TSLA          300            0   \n",
      "1  2024-12-19 09:00:00.012234472+00:00   TSLA          300          300   \n",
      "2  2024-12-19 09:00:00.014157632+00:00   TSLA          200          300   \n",
      "3  2024-12-19 09:00:00.014191599+00:00   TSLA          200          200   \n",
      "4  2024-12-19 09:00:00.017483329+00:00   TSLA          200          200   \n",
      "\n",
      "   ofi_level_2  ofi_level_3  ofi_level_4  \n",
      "0            0            0            0  \n",
      "1            0            0            0  \n",
      "2          300            0            0  \n",
      "3          300          300            0  \n",
      "4          300          300          700  \n",
      "\n",
      "Basic OFI Statistics for each stock:\n",
      "\n",
      "BKR:\n",
      "count    328354.000000\n",
      "mean        -28.733583\n",
      "std         848.720832\n",
      "min      -18157.000000\n",
      "25%        -276.000000\n",
      "50%         -32.000000\n",
      "75%         188.000000\n",
      "max       18876.000000\n",
      "Name: ofi_level_0, dtype: float64\n",
      "\n",
      "MARA:\n",
      "count    618384.000000\n",
      "mean        -67.662077\n",
      "std        5969.446893\n",
      "min      -86169.000000\n",
      "25%        -753.000000\n",
      "50%         -86.000000\n",
      "75%         466.000000\n",
      "max      158644.000000\n",
      "Name: ofi_level_0, dtype: float64\n",
      "\n",
      "NVDA:\n",
      "count    4.539735e+06\n",
      "mean     2.018131e+01\n",
      "std      2.306010e+03\n",
      "min     -8.112400e+04\n",
      "25%     -1.620000e+02\n",
      "50%     -5.000000e+00\n",
      "75%      1.450000e+02\n",
      "max      1.440880e+05\n",
      "Name: ofi_level_0, dtype: float64\n",
      "\n",
      "TSLA:\n",
      "count    2.815095e+06\n",
      "mean     9.460358e+01\n",
      "std      1.787486e+03\n",
      "min     -2.416800e+04\n",
      "25%     -7.900000e+01\n",
      "50%      3.000000e+00\n",
      "75%      8.900000e+01\n",
      "max      5.152700e+04\n",
      "Name: ofi_level_0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Read and display the cross-impact matrix\n",
    "cross_impact = pd.read_csv(results_dir / 'cross_impact_matrix.csv', index_col=0)\n",
    "print(\"Cross-Impact Matrix:\")\n",
    "print(cross_impact)\n",
    "\n",
    "# Check one of the individual OFI results (let's look at TSLA)\n",
    "tsla_ofi = pd.read_csv(results_dir / 'ofi_results_TSLA.csv')\n",
    "print(\"\\nTSLA OFI Results (first few rows):\")\n",
    "print(tsla_ofi.head())\n",
    "\n",
    "# Get basic statistics of OFI for each stock\n",
    "print(\"\\nBasic OFI Statistics for each stock:\")\n",
    "for file in results_dir.glob('ofi_results_*.csv'):\n",
    "    df = pd.read_csv(file)\n",
    "    symbol = df['symbol'].iloc[0]\n",
    "    print(f\"\\n{symbol}:\")\n",
    "    print(df['ofi_level_0'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48321e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create heatmap of cross-impact matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cross_impact, \n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            fmt='.4f')\n",
    "plt.title('Cross-Impact Matrix Heatmap')\n",
    "plt.savefig(results_dir / 'cross_impact_detailed_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# Create comparison of OFI distributions\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
    "stocks = ['BKR', 'NVDA', 'MARA', 'TSLA']\n",
    "\n",
    "for idx, stock in enumerate(stocks):\n",
    "    i, j = divmod(idx, 2)\n",
    "    df = pd.read_csv(results_dir / f'ofi_results_{stock}.csv')\n",
    "    sns.histplot(data=df, x='ofi_level_0', bins=50, ax=ax[i,j])\n",
    "    ax[i,j].set_title(f'{stock} OFI Distribution')\n",
    "    ax[i,j].set_xlabel('OFI Level 0')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / 'ofi_distributions.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "360439d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in results directory:\n",
      "- cross_impact_detailed_heatmap.png\n",
      "- cross_impact_heatmap.png\n",
      "- ofi_distributions.png\n"
     ]
    }
   ],
   "source": [
    "# Check if new visualization files were created\n",
    "print(\"Files in results directory:\")\n",
    "for file in results_dir.glob('*.png'):\n",
    "    print(f\"- {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c00f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced analysis completed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import datetime as dt\n",
    "\n",
    "def enhance_analysis():\n",
    "    \"\"\"Add PCA and lagged analysis to our existing results\"\"\"\n",
    "    results_dir = project_root / 'results'\n",
    "    stocks = ['BKR', 'NVDA', 'MARA', 'TSLA']\n",
    "    \n",
    "    # 1. PCA Analysis\n",
    "    all_ofi_levels = {}\n",
    "    for stock in stocks:\n",
    "        df = pd.read_csv(results_dir / f'ofi_results_{stock}.csv')\n",
    "        ofi_columns = [col for col in df.columns if 'ofi_level' in col]\n",
    "        ofi_matrix = df[ofi_columns].values\n",
    "        \n",
    "        # Apply PCA\n",
    "        pca = PCA()\n",
    "        pca_result = pca.fit_transform(ofi_matrix)\n",
    "        \n",
    "        # Save PCA results\n",
    "        pca_df = pd.DataFrame(\n",
    "            pca_result[:, :2],  # Keep first two components\n",
    "            columns=['PC1', 'PC2']\n",
    "        )\n",
    "        pca_df['symbol'] = stock\n",
    "        pca_df['ts_event'] = pd.to_datetime(df['ts_event'])\n",
    "        pca_df.to_csv(results_dir / f'pca_results_{stock}.csv', index=False)\n",
    "        \n",
    "        # Save explained variance\n",
    "        explained_var = pd.DataFrame({\n",
    "            'component': range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "            'explained_variance_ratio': pca.explained_variance_ratio_\n",
    "        })\n",
    "        explained_var.to_csv(results_dir / f'explained_variance_{stock}.csv', index=False)\n",
    "    \n",
    "    # 2. Lagged Analysis (1-min and 5-min)\n",
    "    lag_periods = [1, 5]  # minutes\n",
    "    for stock in stocks:\n",
    "        df = pd.read_csv(results_dir / f'ofi_results_{stock}.csv')\n",
    "        df['ts_event'] = pd.to_datetime(df['ts_event'])\n",
    "        \n",
    "        # Resample to 1-minute intervals\n",
    "        df.set_index('ts_event', inplace=True)\n",
    "        resampled = df['ofi_level_0'].resample('1T').mean()\n",
    "        \n",
    "        # Calculate lagged correlations\n",
    "        lag_results = []\n",
    "        for lag in lag_periods:\n",
    "            corr = resampled.corr(resampled.shift(lag))\n",
    "            lag_results.append({\n",
    "                'stock': stock,\n",
    "                'lag_minutes': lag,\n",
    "                'autocorrelation': corr\n",
    "            })\n",
    "        \n",
    "        # Save lag analysis\n",
    "        lag_df = pd.DataFrame(lag_results)\n",
    "        lag_df.to_csv(results_dir / f'lag_analysis_{stock}.csv', index=False)\n",
    "\n",
    "    print(\"Enhanced analysis completed\")\n",
    "    \n",
    "# Run enhanced analysis\n",
    "enhance_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cc35bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional visualizations created successfully\n"
     ]
    }
   ],
   "source": [
    "# Enhanced visualizations\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# 1. Time Series Analysis of OFI\n",
    "def create_time_series_plot():\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for stock in ['BKR', 'NVDA', 'MARA', 'TSLA']:\n",
    "        df = pd.read_csv(results_dir / f'ofi_results_{stock}.csv')\n",
    "        df['ts_event'] = pd.to_datetime(df['ts_event'])\n",
    "        # Resample to 5-minute intervals for better visualization\n",
    "        df.set_index('ts_event', inplace=True)\n",
    "        ofi_resampled = df['ofi_level_0'].resample('5T').mean()\n",
    "        plt.plot(ofi_resampled.index, ofi_resampled.values, label=stock)\n",
    "    \n",
    "    plt.title('OFI Time Series (5-minute intervals)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('OFI Level 0')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / 'ofi_time_series.png')\n",
    "    plt.close()\n",
    "\n",
    "# 2. Multi-level OFI Analysis\n",
    "def create_multilevel_comparison():\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "    \n",
    "    for idx, stock in enumerate(['BKR', 'NVDA', 'MARA', 'TSLA']):\n",
    "        i, j = divmod(idx, 2)\n",
    "        ax = fig.add_subplot(gs[i, j])\n",
    "        \n",
    "        df = pd.read_csv(results_dir / f'ofi_results_{stock}.csv')\n",
    "        for level in range(5):\n",
    "            sns.kdeplot(data=df[f'ofi_level_{level}'], label=f'Level {level}', ax=ax)\n",
    "        \n",
    "        ax.set_title(f'{stock} OFI Distribution Across Levels')\n",
    "        ax.set_xlabel('OFI Value')\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / 'multilevel_ofi_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "# 3. Box Plot Analysis\n",
    "def create_box_plots():\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    box_data = []\n",
    "    labels = []\n",
    "    for stock in ['BKR', 'NVDA', 'MARA', 'TSLA']:\n",
    "        df = pd.read_csv(results_dir / f'ofi_results_{stock}.csv')\n",
    "        box_data.append(df['ofi_level_0'])\n",
    "        labels.append(stock)\n",
    "    \n",
    "    plt.boxplot(box_data, labels=labels, showfliers=False)\n",
    "    plt.title('OFI Distribution Comparison')\n",
    "    plt.ylabel('OFI Level 0')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(results_dir / 'ofi_boxplot_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "# Create all visualizations\n",
    "try:\n",
    "    create_time_series_plot()\n",
    "    create_multilevel_comparison()\n",
    "    create_box_plots()\n",
    "    print(\"Additional visualizations created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating visualizations: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "511a6f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
